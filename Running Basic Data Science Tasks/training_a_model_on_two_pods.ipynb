{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea7cf46",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bitfount/tutorials/blob/main/Running%20Basic%20Data%20Science%20Tasks/training_a_model_on_two_pods.ipynb)\n",
    "\n",
    "# Training a Model on Two Pods\n",
    "\n",
    "In this tutorial you will learn how to train a model on two Pods. We will use the Pods you set up in \"Running a Pod\" and \"Running a Pod Using YAML\", so make sure you run those tutorials first. Double check that both Pods from the tutorials are online in the Hub.\n",
    "\n",
    "If you haven't yet trained a model, you should review \"Querying and Training a Model\" as this tutorial will build from there.\n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitfount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f14277",
   "metadata": {},
   "source": [
    "### The Pods\n",
    "\n",
    "This tutorial uses the same census income pods as \"Running a Pod\" and \"Running a Pod Using YAML\", which you should already have access to.\n",
    "\n",
    "### Running a simple model\n",
    "\n",
    "Let's import the relevant pieces for the query or model we wish to train from our API reference. Note: These may differ if you wish to use a different protocol or algorithm, so keep that in mind if looking to execute a different type of task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e42118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from bitfount import (\n",
    "    BitfountSchema,\n",
    "    DataStructure,\n",
    "    Optimizer,\n",
    "    PyTorchTabularClassifier,\n",
    "    SecureAggregator,\n",
    "    combine_pod_schemas,\n",
    "    get_pod_schema,\n",
    "    setup_loggers,\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()  # Needed because Jupyter also has an asyncio loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e1ebb",
   "metadata": {},
   "source": [
    "Let's set up the loggers. The loggers are necessary to ensure you can receive real-time feedback on your task's progress or error messages if something goes wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90297a",
   "metadata": {
    "tags": [
     "logger_setup"
    ]
   },
   "outputs": [],
   "source": [
    "loggers = setup_loggers([logging.getLogger(\"bitfount\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa89c29",
   "metadata": {},
   "source": [
    "The config for training on two Pods is very similar to that of training on one as in \"Querying and Training a Model\", but now you will be training on two different datasets.\n",
    "This means you need to list both Pods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62988de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pod_identifier = \"census-income-demo-dataset\"\n",
    "second_pod_identifier = \"census-income-yaml-demo-dataset\"\n",
    "datastructure = DataStructure(\n",
    "    target=\"TARGET\",\n",
    "    table={\n",
    "        \"census-income-demo-dataset\": \"census-income-demo-dataset\",\n",
    "        \"census-income-yaml-demo-dataset\": \"census-income-yaml-demo-dataset\",\n",
    "    },\n",
    ")\n",
    "schema = combine_pod_schemas([first_pod_identifier, second_pod_identifier])\n",
    "\n",
    "model = PyTorchTabularClassifier(\n",
    "    datastructure=datastructure,\n",
    "    schema=schema,\n",
    "    epochs=2,\n",
    "    batch_size=64,\n",
    "    optimizer=Optimizer(name=\"SGD\", params={\"lr\": 0.001}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee083d2",
   "metadata": {},
   "source": [
    "In this tutorial, we will also use [secure aggregation](https://eprint.iacr.org/2017/281.pdf) for\n",
    "aggregating and computing the averages across the model parameters from the pods.\n",
    "In order to use secure aggregation, we specify an additional parameter `aggregator = SecureAggregator()`\n",
    "in the model `fit` method.\n",
    "The `SecureAggregator` is essentially a secure multi-party computation algorithm based on additive secret sharing. Its goal is to compute weight averages, without revealing the raw weight values resulting from training input Pod data accessible to end-users.\n",
    "The secret sharing algorithm works as follows:\n",
    "\n",
    "1. First every worker shares a securely generated random number (between 0 and a\n",
    "   `prime_q`, which is set by default to 2<sup>61</sup>-1) with every other worker\n",
    "   such that every worker ends up with one number from every other worker.\n",
    "   These numbers are known as shares as they will form part of the secret (the weight\n",
    "   update), which will be shared.\n",
    "2. The tensors in the weight update are then converted to positive integer field\n",
    "   elements of a finite field bounded by `prime_q`.\n",
    "3. The random numbers generated are used to compute a final share for every\n",
    "   tensor in the weight update. This final share has the same shape as the secret\n",
    "   tensor.\n",
    "4. This final share is then reconstructed using the shares retrieved from the\n",
    "   other workers. At this point, the final share from each worker is meaningless\n",
    "   until averaged with every other weight update.\n",
    "5. This final share is sent to the modeller where it will be averaged with the\n",
    "   updates from all the other workers (all the while in the finite field space).\n",
    "6. After averaging, the updates are finally decoded back to floating point\n",
    "   tensors.\n",
    "\n",
    "Note that `SecureAggregation` can be done only on Pods that have been approved to work with one another.\n",
    "If you look back at \"Running a Pod\" tutorial, we specified `census-income-demo-dataset` as part of the `approved_pods` when\n",
    "defining the `census-income-demo-dataset` Pod, and in \"Running a Pod using YAML\" we specified `census-income-demo-dataset` as one of the `other_pods`\n",
    "that the `census-income-yaml-demo-dataset` Pod can work with for secure aggregation.\n",
    "\n",
    "That's all the setup and explanations, let's run the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a124a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    pod_identifiers=[first_pod_identifier, second_pod_identifier],\n",
    "    aggregator=SecureAggregator(),\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b996f",
   "metadata": {},
   "source": [
    "Let's also serialize and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de227f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = Path(\"training_a_model_on_two_pods.pt\")\n",
    "model.serialize(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f2c0a",
   "metadata": {},
   "source": [
    "Contact our support team at [support@bitfount.com](mailto:support@bitfount.com) if you have any questions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "hide_notebook_metadata": true,
   "root_level_metadata": {
    "hide_title": true,
    "sidebar_label": "Training a Model on two Pods",
    "sidebar_position": 2,
    "slug": "/running-basic-data-science-tasks/training-a-model-on-two-pods"
   },
   "root_level_metadata_as_raw_cell": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
