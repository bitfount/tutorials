{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12f3519",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bitfount/tutorials/blob/main/Running%20Basic%20Data%20Science%20Tasks/querying_and_training_a_model.ipynb)\n",
    "\n",
    "# Querying and Training a Model\n",
    "\n",
    "In this tutorial we will first learn how to execute SQL queries on a Pod, then understand how to train a model on a federated dataset.\n",
    "You will use the Pod you set up in \"Running a Pod\", so make sure the Pod is showing as 'Online' in your Bitfount Hub 'My Pods' view. If it is 'Offline,' run the Pod again following the instructions in \"Running a Pod\".\n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitfount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af44449",
   "metadata": {},
   "source": [
    "### Obtaining access\n",
    "\n",
    "Typically, you will need to receive access to a Pod from the Data Custodian who owns the Pod to query or train on its associated data. The Data Custodian will need your Bitfount username to grant you access. Once access is granted, you will be able to view whether the Pod is online and what permissions you have to it in the \"Accessible Pods\" view in the Hub.\n",
    "\n",
    "For the purposes of this tutorial, you will be using the pod you set up in \"Running a Pod\", so you won't need to gain any access.\n",
    "\n",
    "Let's import the relevant pieces for the query or model we wish to train from our API reference. Note: These may differ if you wish to use a different protocol or algorithm, so keep that in mind if looking to execute a different type of task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "from bitfount import (\n",
    "    DataStructure,\n",
    "    FederatedAveraging,\n",
    "    FederatedModelTraining,\n",
    "    Optimizer,\n",
    "    PyTorchTabularClassifier,\n",
    "    SqlQuery,\n",
    "    get_pod_schema,\n",
    "    setup_loggers,\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()  # Needed because Jupyter also has an asyncio loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b93653",
   "metadata": {},
   "source": [
    "Let's set up the loggers. The loggers are necessary to ensure you can receive real-time feedback on your task's progress or error messages if something goes wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc7d86",
   "metadata": {
    "tags": [
     "logger_setup"
    ]
   },
   "outputs": [],
   "source": [
    "loggers = setup_loggers([logging.getLogger(\"bitfount\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5f8c6",
   "metadata": {},
   "source": [
    "### Querying a pod\n",
    "\n",
    "We can run a SQL query on a Pod by specifying our query as a parameter to the `SQLQuery` algorithm. We then pass the `pod_identifier(s)`, i.e. the dataset name on which we would like to execute the query. Before executing the query, double check that the `census-income-demo-dataset` Pod is online in the Hub.\n",
    "\n",
    "This is the mechanism for running a SQL query when no differential privacy restrictions have been placed on the Pod. For details on how to run a query with privacy-preserving controls, see \"Privacy-preserving Techniques\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_identifier = \"census-income-demo-dataset\"\n",
    "query = SqlQuery(\n",
    "    query=\"\"\"\n",
    "\n",
    "SELECT occupation, AVG(age)\n",
    "FROM `census-income-demo-dataset`\n",
    "GROUP BY occupation\n",
    "\"\"\"\n",
    ")\n",
    "query_result = query.execute(pod_identifiers=[pod_identifier])\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d570dc",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "Here we outline how to train a model by leveraging the Bitfount Python API.\n",
    "\n",
    "Typically, when training a model, there are a few parameters to specify in the configuration for this training run.\n",
    "\n",
    "- `pod identifier`: The list of Pods that hold the data you want to train on\n",
    "- `data structure`: The structure of the data on which we will train the model. It contains the target column, columns to select/ignore for training.\n",
    "- `schema`: For training a model on a Pod, we need to download the Pod schema.\n",
    "- `protocol`: The federated learning protocol to use. Note that you must have approval from the Pod!\n",
    "- `algorithm`: The federated learning algorithm to use.\n",
    "- `aggregator`: This may be required depending on your chosen protocol\n",
    "- `model`: The model you want to train\n",
    "- `model hyperparameters`: The settings used by the model\n",
    "\n",
    "For this tutorial, we will use the default protocol (Federated Averaging) and Algorithm (Federated Model Training).\n",
    "In the \"Differential Privacy\" tutorial, we will show you how to change the default protocol and algorithm.\n",
    "\n",
    "Let's define the model that we will use and the relevant data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_identifier = \"census-income-demo-dataset\"\n",
    "schema = get_pod_schema(pod_identifier)\n",
    "\n",
    "model = PyTorchTabularClassifier(\n",
    "    datastructure=DataStructure(target=\"TARGET\", table=\"census-income-demo-dataset\"),\n",
    "    schema=schema,\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    optimizer=Optimizer(name=\"SGD\", params={\"lr\": 0.001}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a3a99",
   "metadata": {},
   "source": [
    "That's all the setup, let's run the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02671fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(pod_identifiers=[pod_identifier])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70700390",
   "metadata": {},
   "source": [
    "Let's also serialize and save the model, as we will need it in one of the later tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = Path(\"training_a_model.pt\")\n",
    "model.serialize(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369e7b9",
   "metadata": {},
   "source": [
    "Above you ran `model.fit()` to train your model. As a result, the `bitfount` package set up the `FederatedAveraging` protocol for you. Alternatively, we can achieve the equivalent by explicitly specifying the protocol we want and calling `.run()`. We demonstrate this below with the `FederatedAveraging` protocol to replicate the results, but this can be switched out for any protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = FederatedAveraging(algorithm=FederatedModelTraining(model=model))\n",
    "protocol_results = protocol.run(pod_identifiers=[pod_identifier])\n",
    "print(protocol_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc990b1",
   "metadata": {},
   "source": [
    "Contact our support team at [support@bitfount.com](mailto:support@bitfount.com) if you have any questions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "hide_notebook_metadata": true,
   "root_level_metadata": {
    "hide_title": true,
    "sidebar_label": "Querying and Training a Model",
    "sidebar_position": 1,
    "slug": "/running-basic-data-science-tasks/querying-and-training-a-model"
   },
   "root_level_metadata_as_raw_cell": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
