{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a089f7f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bitfount/tutorials/blob/main/Advanced%20Data%20Science%20Tasks/training_a_custom_segmentation_model.ipynb)\n",
    "\n",
    "# Training a Custom Segmentation Model\n",
    "\n",
    "In this tutorial you will learn how to train a model using a custom segmentation model by extending a base model in the Bitfount framework. We will use the Pod you will need to set up in the \"Running a Segmentation Data Pod\" tutorial, so make sure it is online. If it is offline, you can re-start it by running the Running a Segmentation Data Pod tutorial again.\n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b95439",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitfount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48500a",
   "metadata": {},
   "source": [
    "### Setting everything up\n",
    "\n",
    "Let's import the relevant pieces from the API Reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e90bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  # isort: split\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "# Update the class name for your Custom model\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from bitfount import (\n",
    "    SEGMENTATION_METRICS,\n",
    "    BitfountModelReference,\n",
    "    BitfountSchema,\n",
    "    DataStructure,\n",
    "    PyTorchBitfountModel,\n",
    "    SoftDiceLoss,\n",
    "    get_pod_schema,\n",
    "    setup_loggers,\n",
    ")\n",
    "\n",
    "nest_asyncio.apply()  # Needed because Jupyter also has an asyncio loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869595c1",
   "metadata": {},
   "source": [
    "Let's import the loggers, which allow you to monitor progress of your executed commands and raise errors in the event something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2af28",
   "metadata": {
    "tags": [
     "logger_setup"
    ]
   },
   "outputs": [],
   "source": [
    "loggers = setup_loggers([logging.getLogger(\"bitfount\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef08358",
   "metadata": {},
   "source": [
    "### Creating a custom model\n",
    "\n",
    "As in the Training a Custom Model tutorial, for this tutorial we will be creating a custom model and extending and overriding the built-in `BitfountModel` class (in particular we will be using the `PyTorchBitfountModel` class). Details on this can be found in the documentation in the `bitfount.backends.pytorch.models.bitfount_model` module.\n",
    "\n",
    "The `PyTorchBitfountModel` uses the [PyTorch Lightning](https://www.pytorchlightning.ai/) library to provide high-level implementation options for a model in the PyTorch framework. This enables you to only have to implement the methods you need to dictate how the model training should be performed.\n",
    "\n",
    "For our custom model we _need_ to implement the following methods:\n",
    "\n",
    "- `__init__()`: how to setup the model\n",
    "- `configure_optimizers()`: how optimizers should be configured in the model\n",
    "- `forward()`: how to perform a forward pass in the model, how the loss is calculated\n",
    "- `training_step()`: what one training step in the model looks like\n",
    "- `validation_step()`: what one validation step in the model looks like\n",
    "- `test_step()`: what one test step in the model looks like\n",
    "\n",
    "Now we'll show you how to implement the custom segmentation model, but feel free to try out your own model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyCustomSegmentationModel(PyTorchBitfountModel):\n",
    "    # Implementation of a UNet model, used for testing purposes.\n",
    "    def __init__(self, n_channels=3, n_classes=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = True\n",
    "        self.dice_loss = SoftDiceLoss()\n",
    "        self.ce_loss = torch.nn.CrossEntropyLoss()\n",
    "        self.metrics = SEGMENTATION_METRICS\n",
    "\n",
    "    def create_model(self):\n",
    "        class UNet(nn.Module):\n",
    "            def __init__(self, n_channels, n_classes, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "\n",
    "                self.n_channels = n_channels\n",
    "                self.n_classes = n_classes\n",
    "\n",
    "                def double_conv(in_channels, out_channels):\n",
    "                    return nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    )\n",
    "\n",
    "                def down(in_channels, out_channels):\n",
    "                    return nn.Sequential(\n",
    "                        nn.MaxPool2d(2), double_conv(in_channels, out_channels)\n",
    "                    )\n",
    "\n",
    "                class up(nn.Module):\n",
    "                    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "                        super().__init__()\n",
    "\n",
    "                        if bilinear:\n",
    "                            self.up = nn.Upsample(\n",
    "                                scale_factor=2, mode=\"bilinear\", align_corners=True\n",
    "                            )\n",
    "                        else:\n",
    "                            self.up = nn.ConvTranpose2d(\n",
    "                                in_channels // 2,\n",
    "                                in_channels // 2,  # noqa: B950\n",
    "                                kernel_size=2,\n",
    "                                stride=2,\n",
    "                            )\n",
    "                        self.conv = double_conv(in_channels, out_channels)\n",
    "\n",
    "                    def forward(self, x1, x2):\n",
    "                        x1 = self.up(x1)\n",
    "                        # [Batch size, Channels, Height, Width]\n",
    "                        diffY = x2.size()[2] - x1.size()[2]\n",
    "                        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "                        x1 = F.pad(\n",
    "                            x1,\n",
    "                            [\n",
    "                                diffX // 2,\n",
    "                                diffX - diffX // 2,\n",
    "                                diffY // 2,\n",
    "                                diffY - diffY // 2,\n",
    "                            ],\n",
    "                        )\n",
    "                        x = torch.cat([x2, x1], dim=1)\n",
    "                        return self.conv(x)\n",
    "\n",
    "                self.inc = double_conv(self.n_channels, 64)\n",
    "                self.down1 = down(64, 128)\n",
    "                self.down2 = down(128, 256)\n",
    "                self.down3 = down(256, 512)\n",
    "                self.down4 = down(512, 512)\n",
    "                self.up1 = up(1024, 256)\n",
    "                self.up2 = up(512, 128)\n",
    "                self.up3 = up(256, 64)\n",
    "                self.up4 = up(128, 64)\n",
    "                self.out = nn.Conv2d(64, self.n_classes, kernel_size=1)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x1 = self.inc(x)\n",
    "                x2 = self.down1(x1)\n",
    "                x3 = self.down2(x2)\n",
    "                x4 = self.down3(x3)\n",
    "                x5 = self.down4(x4)\n",
    "                x = self.up1(x5, x4)\n",
    "                x = self.up2(x, x3)\n",
    "                x = self.up3(x, x2)\n",
    "                x = self.up4(x, x1)\n",
    "                return self.out(x)\n",
    "\n",
    "        return UNet(self.n_channels, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def split_dataloader_output(self, data):\n",
    "        # During the data loading process some extra columns are added.\n",
    "        # For the purpose of this tutorial we only need the images,\n",
    "        # so we separate those from the actual images.\n",
    "        images, sup = data\n",
    "        weights = sup[:, 0].float()\n",
    "        if sup.shape[1] > 2:\n",
    "            category = sup[:, -1].long()\n",
    "        else:\n",
    "            category = None\n",
    "        return images, weights, category\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        x, *sup = self.split_dataloader_output(x)\n",
    "        y = y[:, 0].long()\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        # Cross entropy loss\n",
    "        ce_loss = (\n",
    "            F.cross_entropy(y_hat, y)\n",
    "            if self.n_classes > 1\n",
    "            else F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        )  # noqa: B950\n",
    "\n",
    "        return {\"loss\": ce_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        x, *sup = self.split_dataloader_output(x)\n",
    "        # Get rid of the number of channels dimension and make targets of type `long`\n",
    "        y = y[:, 0].long()\n",
    "        y_hat = self.forward(x)\n",
    "        softmax_y_hat = F.softmax(y_hat, dim=1)\n",
    "\n",
    "        # Cross entropy loss\n",
    "        ce_loss = (\n",
    "            F.cross_entropy(y_hat, y)\n",
    "            if self.n_classes > 1\n",
    "            else F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        )  # noqa: B950\n",
    "        # dice loss\n",
    "        dice_loss = self.dice_loss(softmax_y_hat, y)\n",
    "        # total loss\n",
    "        total_loss = (ce_loss + dice_loss) / 2\n",
    "        # We can log out some useful stats so we can see progress\n",
    "        self.log(\"ce_loss\", ce_loss, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            \"ce_loss\": ce_loss,\n",
    "            \"dice_loss\": dice_loss,\n",
    "            \"loss\": total_loss,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        mean_outputs = {}\n",
    "        for k in outputs[0].keys():\n",
    "            mean_outputs[k] = torch.stack([x[k] for x in outputs]).mean()\n",
    "        # Add the means to the validation stats.\n",
    "        self.val_stats.append(mean_outputs)\n",
    "\n",
    "        # Also log out these averaged metrics\n",
    "        for k, v in mean_outputs.items():\n",
    "            self.log(f\"avg_{k}\", v)\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        x, *sup = self.split_dataloader_output(x)\n",
    "        # Get rid of the number of channels dimension and make targets of type `long`\n",
    "        y = y[:, 0].long()\n",
    "\n",
    "        # Get validation output and predictions\n",
    "        y_hat = self.forward(x)\n",
    "        pred = F.softmax(y_hat, dim=1)\n",
    "\n",
    "        # Output targets and prediction for later\n",
    "        return {\"predictions\": pred, \"targets\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011a68f",
   "metadata": {},
   "source": [
    "### Training on a Pod with your own custom segmentation model\n",
    "\n",
    "If you have defined your segmentation model locally, you can train on a remote Pod by providing the Pod identifiers as an argument to the `.fit` method.\n",
    "\n",
    "**NOTE:** Your model will be uploaded to the Bitfount Hub during this process. Models uploaded to the Hub are public by default, so please be sure you are happy for your model structure to be searchable by others before uploading. You can view your uploaded models here: https://hub.bitfount.com/my-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastructure = DataStructure(\n",
    "    table=\"segmentation-data-demo-dataset\", image_cols=[\"img\", \"masks\"], target=\"masks\"\n",
    ")\n",
    "pod_identifier = \"segmentation-data-demo-dataset\"\n",
    "schema = get_pod_schema(pod_identifier)\n",
    "model = MyCustomSegmentationModel(\n",
    "    datastructure=datastructure, schema=schema, epochs=1, batch_size=5\n",
    ")\n",
    "results = model.fit(\n",
    "    pod_identifiers=[pod_identifier],\n",
    "    model_out=Path(\"training_a_custom_segmentation_model.pt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab08849",
   "metadata": {},
   "source": [
    "Congrats! You've now successfully trained a custom segmentation model.\n",
    "\n",
    "Contact our support team at [support@bitfount.com](mailto:support@bitfount.com) if you have any questions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "hide_notebook_metadata": true,
   "root_level_metadata": {
    "hide_title": true,
    "sidebar_label": "Training a Custom Segmentation Model",
    "sidebar_position": 3,
    "slug": "/advanced-data-science-tasks/training-a-custom-segmentation-model"
   },
   "root_level_metadata_as_raw_cell": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
