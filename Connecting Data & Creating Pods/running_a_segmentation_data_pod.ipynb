{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b97599",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bitfount/tutorials/blob/main/Connecting%20Data%20%26%20Creating%20Pods/running_a_segmentation_data_pod.ipynb)\n",
    "\n",
    "# Running a Pod with a segmentation dataset\n",
    "\n",
    "By the end of this notebook, you will have learned how to run a Pod that uses a segmentation dataset and how to start up a Pod using a `DataSourceContainer` with a `DataFrameSource`.\n",
    "\n",
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitfount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe760bea",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "\n",
    "Let's import the relevant pieces from the API Reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bitfount import DataFrameSource, DatasourceContainerConfig, Pod, setup_loggers\n",
    "from bitfount.runners.config_schemas import PodConfig, PodDataConfig, PodDetailsConfig\n",
    "from bitfount.utils import ExampleSegmentationData\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "\n",
    "nest_asyncio.apply()  # Needed because Jupyter also has an asyncio loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5cb2d",
   "metadata": {},
   "source": [
    "Let's import the loggers, which allow you to monitor progress of your executed commands and raise errors in the event something goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dad57",
   "metadata": {
    "tags": [
     "logger_setup"
    ]
   },
   "outputs": [],
   "source": [
    "loggers = setup_loggers([logging.getLogger(\"bitfount\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53b7e0",
   "metadata": {},
   "source": [
    "### Setting up the Pod\n",
    "\n",
    "We now specify the config for the Pod to run. For this tutorial we will generate synthetic images and masks and save them to the local system in a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory where we save the images\n",
    "seg_dir = \"segmentation\"\n",
    "# Check if the folder exists and create it if not\n",
    "path = Path(seg_dir + \"/\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "# Set the number of images to generate\n",
    "count = 25\n",
    "# Set the height and width of the images\n",
    "height = 100\n",
    "width = 100\n",
    "# Get the example segmentation dataset\n",
    "segmentation_data = ExampleSegmentationData()\n",
    "# Generate the images\n",
    "input_images, target_masks = segmentation_data.generate_data(height, width, count=count)\n",
    "# Change channel-order and make 3 channels\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [\n",
    "    segmentation_data.masks_to_colorimg(x.astype(np.uint8)) for x in target_masks\n",
    "]\n",
    "img_names_list = []\n",
    "masks_names_list = []\n",
    "# Save images\n",
    "for i in range(count):\n",
    "    im2 = Image.fromarray((input_images_rgb[i]).astype(np.uint8))\n",
    "    im2.save(f\"{seg_dir}/img_{i}.png\")\n",
    "    img_names_list.append(f\"img_{i}.png\")\n",
    "# Save masks\n",
    "for i in range(count):\n",
    "    im2 = Image.fromarray((target_masks_rgb[i]).astype(np.uint8))\n",
    "    im2.save(f\"{seg_dir}/masks_{i}.png\")\n",
    "    masks_names_list.append(f\"masks_{i}.png\")\n",
    "\n",
    "# Create dataframe with image and masks locations\n",
    "segmentation_df = pd.DataFrame(\n",
    "    {\n",
    "        \"img\": [str(seg_dir) + \"/\" + img_name for img_name in img_names_list],\n",
    "        \"masks\": [str(seg_dir) + \"/\" + mask_name for mask_name in masks_names_list],\n",
    "    },\n",
    "    columns=[\"img\", \"masks\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7745e0",
   "metadata": {},
   "source": [
    "Segmentation datasets are slightly different from image datasets (for which you saw an example in the \"Training on Images\" tutorial), as they allow both training and predictions on images. For segmentation datasets, the DataSource will need to have references to the images you want to train with as well as the images you use as the target for the machine learning task you are performing. Therefore, we must inform the Pod that the contents of this column hold references to both images for training and target images for the task. We achieve this by specifying the columns as `\"image\"` through the `force_stypes` parameter in the `PodDataConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_data_config = PodDataConfig(\n",
    "    force_stypes={\"segmentation-data-demo-dataset\": {\"image\": [\"img\", \"masks\"]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a pod using the generated, synthetic images and masks.\n",
    "datasource = DataFrameSource(segmentation_df)\n",
    "datasource_details = PodDetailsConfig(\n",
    "    display_name=\"Segmentation Demo Pod\",\n",
    "    description=\"This Pod contains generated, synthetic data for a segmentation task.\",\n",
    ")\n",
    "pod = Pod(\n",
    "    name=\"segmentation-data-demo\",\n",
    "    datasources=[\n",
    "        DatasourceContainerConfig(\n",
    "            name=\"segmentation-data-demo-dataset\",\n",
    "            datasource=datasource,\n",
    "            datasource_details=PodDetailsConfig(\n",
    "                display_name=\"Segmentation Demo Pod\",\n",
    "                description=\"This Pod contains generated, synthetic data for a segmentation task.\",\n",
    "            ),\n",
    "            data_config=segmentation_data_config,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7137334",
   "metadata": {},
   "source": [
    "### Running the Pod\n",
    "\n",
    "That's all of the set up. Let's run the Pod. You'll notice that the notebook cell doesn't complete. That's because the Pod is set to run until it is interrupted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306aca7b",
   "metadata": {},
   "source": [
    "You should now be able to see your Pod as registered in your Datasets page on the [Bitfount Hub](https://am.hub.bitfount.com/datasets). To use the Pod, open up \"Training a Custom Segmentation Model\" in a separate tab, and we'll train a segmentation model on this Pod.\n",
    "\n",
    "Contact our support team at [support@bitfount.com](mailto:support@bitfount.com) if you have any questions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "hide_notebook_metadata": true,
   "root_level_metadata": {
    "hide_title": true,
    "sidebar_label": "Running a Segmentation data Pod",
    "sidebar_position": 4,
    "slug": "/connecting-data-and-creating-pods/running-a-segmentation-data-pod"
   },
   "root_level_metadata_as_raw_cell": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
